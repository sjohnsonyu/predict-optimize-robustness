{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e0ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import ipdb\n",
    "import pickle\n",
    "from collections import OrderedDict, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd6c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'week': 'week12',\n",
    "    'current_week': 12,\n",
    "    'thresh': 0.5\n",
    "}\n",
    "policies = ['rmab', 'control', 'round_robin']\n",
    "T = 12\n",
    "\n",
    "df = pd.read_csv('outputs/analysis_lists/all_analysis_week_12.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f1a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get users in round robin, rmab and control groups\n",
    "\n",
    "df2 = pd.read_csv('outputs/individual_clustering/weekly_kmeans_pilot_stats_40.csv')\n",
    "\n",
    "\n",
    "rmab_list = pd.read_csv('outputs/pilot_outputs/rmab_pilot.csv')['user_id'].to_list()\n",
    "round_robin_list = pd.read_csv('outputs/pilot_outputs/round_robin_pilot.csv')['user_id'].to_list()\n",
    "control_list = pd.read_csv('outputs/pilot_outputs/control_pilot.csv')['user_id'].to_list()\n",
    "\n",
    "\n",
    "rmab_group = df[df['user_id'].isin(rmab_list)]\n",
    "rmab_group = rmab_group.sort_values('{}_whittle'.format(CONFIG['week']), ascending=False)\n",
    "\n",
    "round_robin_group = df2[df2['user_id'].isin(round_robin_list)]\n",
    "round_robin_group = round_robin_group.sort_values('registration_date', ascending=True)\n",
    "\n",
    "rmab_user_ids = rmab_group['user_id'].to_list()\n",
    "round_robin_user_ids = round_robin_group['user_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58639fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pilot registration data\n",
    "pilot_pd_data = pd.read_csv(\"feb16-mar15_data/beneficiary/ai_registration-20210216-20210315.csv\", sep='\\t')\n",
    "class_based_features = ['ChannelType', 'phone_owner' , \"call_slots\", \"language\"]\n",
    "numeric_features = ['enroll_gest_age', \"enroll_delivery_status\", \n",
    "                    'age_binned', 'g', 'p', 's', 'l', 'a', 'education', 'income_binned']\n",
    "\n",
    "# Bin income and age\n",
    "pilot_pd_data['income_binned'] = pilot_pd_data['income_bracket'].replace(\n",
    "    dict(zip(['0-5000', '5000-10000', '10000-15000', '15000-20000',\n",
    "        '20000-25000', '25000-30000', '30000 and above'], [0,1,2,3,4,5,6])))\n",
    "pilot_pd_data['age_binned'] = pd.cut(pilot_pd_data['age'], bins=5, labels=False)\n",
    "\n",
    "\n",
    "dummy = pd.get_dummies(pilot_pd_data[class_based_features], columns = class_based_features)\n",
    "pilot_pd_data = pd.concat([pilot_pd_data.drop(columns = class_based_features), dummy], axis=1)\n",
    "class_based_features = list(dummy.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54e336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "columns = numeric_features+class_based_features +[\"curr_state\"] +[\"exp_arm_rmab\",\"exp_arm_rr\"]\n",
    "\n",
    "# Reorder and subset pilot_pd_data same as df user_ids\n",
    "pilot_user_ids = df.user_id\n",
    "pilot_static_features = pilot_pd_data[pilot_pd_data['user_id'].isin(pilot_user_ids)][numeric_features+class_based_features+['user_id']]\n",
    "pilot_static_features = pilot_static_features.set_index('user_id')\n",
    "pilot_static_features = pilot_static_features.loc[pilot_user_ids].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d73d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X matrix contains features\n",
    "# Y_mat contains for every time, cumulative engagement upto time T.\n",
    "##   Here weekly engagement is defined as binary - listened to at least one call\n",
    "# Y_all_mat contains cumulative calls listened to. No binarization\n",
    "# C_mat contains cumulative number of calls made upto time t.\n",
    "\n",
    "X_mat, Y_mat, Y_all_mat, C_mat = [], [[] for i in range(1,T)], [[] for i in range(1,T)], [[] for i in range(1,T)]\n",
    "\n",
    "intervention_benefit = {'rmab': [], 'round_robin': [], 'control': []}\n",
    "all_user_ids = set(df['user_id'].to_list())\n",
    "full_mat = {'rmab': [], 'round_robin': [], 'control': []}\n",
    "\n",
    "# this is paired tuple - [does beneficiary belongs to RMAB, does beneficiary belongs to RR]\n",
    "arm_to_cat = {'rmab': [1,0], 'round_robin': [0,1], 'control': [0,0]}\n",
    "\n",
    "# mask defining whether the beneficiary belongs to that group or not. Right now it is all 0,\n",
    "# It will be updated later in the loop.\n",
    "mask = {'rmab':[0]*len(pilot_user_ids), 'round_robin':[0]*len(pilot_user_ids), 'control':[0]*len(pilot_user_ids)}\n",
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab17f621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23003it [00:22, 1036.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, user_id in tqdm(enumerate(pilot_user_ids)):\n",
    "\n",
    "    curr_mat = []\n",
    "    curr_row = df[df['user_id'] == user_id]\n",
    "\n",
    "    # get the arm using df\n",
    "    arm = curr_row['arm'].item()\n",
    "    \n",
    "    count_all = 0 # count of engagements - non binarized\n",
    "    count_bin = 0 # count of engagements - binarized\n",
    "    count_c = 0 # count of number of calls made\n",
    "\n",
    "    week0e, week0c = [int(itr) for itr in curr_row['week{}_E/C'.format(0)].item().split('/')]\n",
    "    count_c += week0c\n",
    "    if week0e:\n",
    "        curr_mat.append(1)\n",
    "        count_all += week0e\n",
    "        count_bin += 1\n",
    "    else:\n",
    "        curr_mat.append(0)\n",
    "    Y_mat[0].append(count_bin)\n",
    "    Y_all_mat[0].append(count_all)\n",
    "    C_mat[0].append(count_c)\n",
    "    for i in range(1,T):\n",
    "        nume, numc = [int(itr) for itr in curr_row['week{}_E/C'.format(i)].item().split('/')]\n",
    "        count_c += numc\n",
    "        if nume > 0:\n",
    "            count_all += nume\n",
    "            count_bin += 1\n",
    "            curr_mat.append(nume)\n",
    "        else:\n",
    "            curr_mat.append(0)\n",
    "        Y_mat[i].append(count_bin)\n",
    "        Y_all_mat[i].append(count_all)\n",
    "        C_mat[i].append(count_c)\n",
    "    X_mat.append(list(pilot_static_features[idx, :]) + [curr_mat[0]]+ arm_to_cat[arm])\n",
    "\n",
    "    # update mask based on arm\n",
    "    mask[arm][ctr] = 1\n",
    "    ctr+=1\n",
    "\n",
    "    full_mat[arm].append(np.array(curr_mat, dtype=np.int))\n",
    "\n",
    "mask = {i:np.array(mask[i][:ctr]) for i in mask}\n",
    "X_mat = np.array(X_mat)\n",
    "Y_mat = np.array(Y_mat)\n",
    "Y_all_mat = np.array(Y_all_mat)\n",
    "C_mat = np.array(C_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3175ea71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 2,  0,  0, ...,  0,  0,  0],\n",
       "       [ 4,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [18,  3,  3, ...,  0,  0,  4],\n",
       "       [20,  3,  3, ...,  0,  0,  5],\n",
       "       [22,  3,  3, ...,  0,  0,  6]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all_mat - Y_all_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "740884c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23003,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2981170",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = CONFIG['thresh']\n",
    "thresh=0.5\n",
    "\n",
    "# has the eneficiaries listened to 50% (thresh) of total calls?\n",
    "Y_thresh_mat = (Y_all_mat > C_mat*thresh).astype(int)\n",
    "Y_adjusted_thresh_mat = ((Y_all_mat-Y_all_mat[0]) > (C_mat-C_mat[0])*thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "971a6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pilot registration data again\n",
    "reg = pd.read_csv('feb16-mar15_data/beneficiary/ai_registration-20210216-20210315.csv', sep='\\t')\n",
    "\n",
    "interv_df = pd.DataFrame(columns=['user_id', 'intervene_week', 'intervene_date', 'exp_group'])\n",
    "interv_calling_files = ['250_week1_290421', '400_week2_060521', '400_week3_120521', '400_week4_180521', '435_week5_240521', '600_week6_310521', '700_week7_070621', '1000_week8_140621', '1000_week9_210621', '1000_week10_280621', '1000_week11_050721']\n",
    "\n",
    "from datetime import datetime\n",
    "# for every file in interv_calling_file - get its date format - 290421 -> 29/04/21\n",
    "week_date_lookup = {int(f.split('_')[1].split('week')[-1]):datetime.strptime(f.split('_')[-1], '%d%m%y') for f in interv_calling_files}\n",
    "\n",
    "for file in interv_calling_files:\n",
    "    with open('outputs/pilot_generations/calling_list_{}.txt'.format(file), 'r') as fr:\n",
    "        for line in fr:\n",
    "            user_id = int(line.strip())\n",
    "            interv_week = int(file.split('_')[1].split('week')[-1])\n",
    "            exp_group = df[df['user_id']==user_id]['arm'].iloc[0]\n",
    "            intervene_date = week_date_lookup[interv_week]\n",
    "            interv_df = interv_df.append({'user_id': user_id, 'intervene_week': interv_week, 'intervene_date':intervene_date, 'exp_group': exp_group}, ignore_index=True)\n",
    "interv_df = pd.merge(interv_df, reg[['user_id', 'registration_date']])  \n",
    "interv_df = pd.merge(interv_df, df[['user_id', 'cluster']])\n",
    "interv_df['registration_date'] = pd.to_datetime(interv_df['registration_date'])\n",
    "interv_df['days_since_reg'] = (interv_df['intervene_date'] - interv_df['registration_date']).dt.days\n",
    "\n",
    "# some of these features arent required but are here nevertheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee0c3933",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: intervene_week'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-826dd2f782c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterv_X_mat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilot_user_ids\u001b[0m \u001b[0;31m# add user_id column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get first week intervened on for every beneficiary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minterv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first_interv_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intervene_week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# note that there could be multiple entries of a beneficiary. Hence lets drop repeated user, first_interv_week pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minterv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_interv_week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m             )\n\u001b[0;32m-> 1603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: intervene_week'"
     ]
    }
   ],
   "source": [
    "# now we need to find whether a beneficiary was intervened by a week t\n",
    "X_mat_df = pd.DataFrame(X_mat, columns=columns)\n",
    "interv_X_mat_df = X_mat_df.copy()\n",
    "interv_X_mat_df['user_id'] = pilot_user_ids # add user_id column\n",
    "# get first week intervened on for every beneficiary\n",
    "interv_df['first_interv_week'] = interv_df.groupby('user_id')['intervene_week'].transform(min) \n",
    "# note that there could be multiple entries of a beneficiary. Hence lets drop repeated user, first_interv_week pairs\n",
    "interv_df = interv_df[['user_id', 'first_interv_week']].drop_duplicates()\n",
    "# now get this variable in our interv_X_mat_df by performing a join\n",
    "interv_X_mat_df = pd.merge(interv_X_mat_df, interv_df, how='left', on='user_id')\n",
    "# those beneficiaries who were never intervened on will be NA. So fill them with a large value \n",
    "# (they were first intervened at week 999 -> implying they werent intervened)\n",
    "interv_X_mat_df['first_interv_week'] = interv_X_mat_df['first_interv_week'].fillna(999)\n",
    "\n",
    "# now add our variable is_intervened_by_week_t as first_interv_week<t. \n",
    "# note that it is < and not <=, because interventions at week t doesn't impact engagements at week t\n",
    "for i in range(1, T):\n",
    "    interv_X_mat_df[f'is_intervened_by_week{i}'] = (interv_X_mat_df['first_interv_week']<i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb453171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some bad columns that cause issue in fitting logistic regression\n",
    "# so better drop them\n",
    "\n",
    "X_mat_df = X_mat_df.drop(columns = [col for col in X_mat_df.columns if col.startswith('phone_owner')]+\n",
    "                        [col for col in X_mat_df.columns if col.startswith('Channel')]+\n",
    "                        [col for col in X_mat_df.columns if col.startswith('call_slots')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04f6a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes columns which have very low variance and cause issue\n",
    "# in logistic regression optimization\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def variance_threshold_selector(data, threshold=0.0001):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beae16d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.31521975, 0.39542668,\n",
       "       0.44189888, 0.47554667, 0.50271704, 0.52393166, 0.54327696,\n",
       "       0.55988349, 0.57449028])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Y_mat-Y_mat[0])>2).astype(int).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393c8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986961a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e87decc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance for T = 1\n",
      "\n",
      "\tRMAB vs RR\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vermashresth/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1810: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Users/vermashresth/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1863: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-1f973b19e319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# notet that we use Logistic regression to model binary outcome var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_mat_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X_mat_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mfii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# the output will have significances in the same order as input dataframe's columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1972\u001b[0m     def fit(self, start_params=None, method='newton', maxiter=35,\n\u001b[1;32m   1973\u001b[0m             full_output=1, disp=1, callback=None, **kwargs):\n\u001b[0;32m-> 1974\u001b[0;31m         bnryfit = super().fit(start_params=start_params,\n\u001b[0m\u001b[1;32m   1975\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m                               \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mpass\u001b[0m  \u001b[0;31m# TODO: make a function factory to have multiple call-backs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         mlefit = super().fit(start_params=start_params,\n\u001b[0m\u001b[1;32m    228\u001b[0m                              \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                              \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mHinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hessian'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "\n",
    "# some helper dicts so as to make code cleaner\n",
    "mask_cols = ['control', 'round_robin', 'rmab']\n",
    "dummy_drop_cols = ['exp_arm_rr', 'exp_arm_rr', 'exp_arm_rmab']\n",
    "dummy_target_cols = ['exp_arm_rmab', 'exp_arm_rmab', 'exp_arm_rr']\n",
    "exps = ['RMAB vs RR', 'RMAB vs Control', 'RR vs Control']\n",
    "\n",
    "for t in range(1, T):\n",
    "    print(f'Significance for T = {t}\\n')\n",
    "    for m, d, tar, e in zip(mask_cols, dummy_drop_cols, dummy_target_cols, exps):\n",
    "        print(f'\\t{e}')\n",
    "        # make dataframe of our Y matrix. use mask to filter on group A, B only for A vs B comparision\n",
    "        # note that we use Y_thresh_mat - which will have binary values\n",
    "        Y_mat_df = pd.DataFrame(((Y_mat[t]-Y_mat[0])>2).astype(int)[t][mask[m]==0],\n",
    "                                columns = ['output'])\n",
    "        # For A vs B comparision, column indicating arm C can be dropped\n",
    "        test_X_mat_df = X_mat_df.drop(columns=d)[mask[m]==0]\n",
    "        test_X_mat_df = test_X_mat_df.drop(columns='curr_state')\n",
    "        # add additional variable of is_intervened_by_week_t using interv_X_mat_df defined earlier\n",
    "#         test_X_mat_df[f'is_intervened_by_week{t}'] = interv_X_mat_df[f'is_intervened_by_week{t}']\n",
    "        # both X and Y dataframes should have same indices else statsmodel throws error\n",
    "        test_X_mat_df.index = np.array(Y_mat_df.index)\n",
    "        # add constant term to the features, and then apply variance selector\n",
    "        test_X_mat_df = variance_threshold_selector(sm.add_constant(test_X_mat_df), 0.0001)\n",
    "\n",
    "        # define and fit the model\n",
    "        # notet that we use Logistic regression to model binary outcome var\n",
    "        mod = sm.Logit(Y_mat_df, test_X_mat_df)\n",
    "        fii = mod.fit()\n",
    "        \n",
    "        # the output will have significances in the same order as input dataframe's columns\n",
    "        # tar is the A vs B comparisions dummy indicator\n",
    "        # look for its position in original columns\n",
    "        index = list(test_X_mat_df.columns).index(tar)\n",
    "        # Get data corresponding to our required variable using the index\n",
    "        # note that we do index + 1 because statsmodel table has header as first entry\n",
    "        var, coef, std_err, t_val, p_val, q1, q3 = fii.summary().tables[1].data[index+1]\n",
    "        print(f'\\t exp: Coef: {coef}, p_val: {p_val}')\n",
    "\n",
    "        try:\n",
    "            # do the same process as above to find signficance of is_intervened_by_week_t variable\n",
    "            index = list(test_X_mat_df.columns).index(f'is_intervened_by_week{t}')\n",
    "            var, coef, std_err, t_val, p_val, q1, q3 = fii.summary().tables[1].data[index+1]\n",
    "            print(f'\\t is_intervened_by_week{t} : Coef: {coef}, p_val: {p_val}')\n",
    "        except:\n",
    "            # note that this code is in try except block because for week 1, is_intervened_by_week_1\n",
    "            # is constant and gets dropped through variance selector function\n",
    "            pass\n",
    "\n",
    "#         print(fii.summary().tables[1])\n",
    "        print('\\n')\n",
    "    print('~'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302ca5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e(t) = r(t) - r(0) -> baseline adjusted weekly eng\n",
    "c(t) = sigma(e(t)) = sigma(r(s)) - t*r(0)\n",
    "\n",
    "c(t) = sigma(r(s)) - r(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a37f80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance for T = 1\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0094, p_val:  0.135\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0066, p_val:  0.295\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0027, p_val:  0.671\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 2\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0225, p_val:  0.036\n",
      "\t is_intervened_by_week2 : Coef:     0.0675, p_val:  0.113\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0168, p_val:  0.118\n",
      "\t is_intervened_by_week2 : Coef:     0.0907, p_val:  0.130\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0045, p_val:  0.673\n",
      "\t is_intervened_by_week2 : Coef:     0.0386, p_val:  0.519\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 3\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0269, p_val:  0.075\n",
      "\t is_intervened_by_week3 : Coef:     0.0464, p_val:  0.218\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0139, p_val:  0.357\n",
      "\t is_intervened_by_week3 : Coef:     0.0740, p_val:  0.158\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0101, p_val:  0.507\n",
      "\t is_intervened_by_week3 : Coef:     0.0162, p_val:  0.760\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 4\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0334, p_val:  0.085\n",
      "\t is_intervened_by_week4 : Coef:     0.0699, p_val:  0.077\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0090, p_val:  0.644\n",
      "\t is_intervened_by_week4 : Coef:     0.1018, p_val:  0.064\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0197, p_val:  0.315\n",
      "\t is_intervened_by_week4 : Coef:     0.0386, p_val:  0.492\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 5\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0367, p_val:  0.121\n",
      "\t is_intervened_by_week5 : Coef:     0.1870, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.0006, p_val:  0.981\n",
      "\t is_intervened_by_week5 : Coef:     0.3092, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0155, p_val:  0.521\n",
      "\t is_intervened_by_week5 : Coef:     0.0686, p_val:  0.242\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 6\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0338, p_val:  0.227\n",
      "\t is_intervened_by_week6 : Coef:     0.3576, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.0387, p_val:  0.175\n",
      "\t is_intervened_by_week6 : Coef:     0.5721, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0206, p_val:  0.475\n",
      "\t is_intervened_by_week6 : Coef:     0.1324, p_val:  0.033\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 7\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0414, p_val:  0.203\n",
      "\t is_intervened_by_week7 : Coef:     0.3661, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.0427, p_val:  0.200\n",
      "\t is_intervened_by_week7 : Coef:     0.5895, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0195, p_val:  0.563\n",
      "\t is_intervened_by_week7 : Coef:     0.1526, p_val:  0.017\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 8\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0525, p_val:  0.155\n",
      "\t is_intervened_by_week8 : Coef:     0.5094, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.0983, p_val:  0.010\n",
      "\t is_intervened_by_week8 : Coef:     0.8598, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0263, p_val:  0.500\n",
      "\t is_intervened_by_week8 : Coef:     0.1863, p_val:  0.004\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 9\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0725, p_val:  0.079\n",
      "\t is_intervened_by_week9 : Coef:     0.7343, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.2260, p_val:  0.000\n",
      "\t is_intervened_by_week9 : Coef:     1.2998, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0411, p_val:  0.358\n",
      "\t is_intervened_by_week9 : Coef:     0.2279, p_val:  0.001\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 10\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.1029, p_val:  0.024\n",
      "\t is_intervened_by_week10 : Coef:     0.9016, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.3483, p_val:  0.000\n",
      "\t is_intervened_by_week10 : Coef:     1.6237, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0512, p_val:  0.312\n",
      "\t is_intervened_by_week10 : Coef:     0.2602, p_val:  0.000\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 11\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.1450, p_val:  0.004\n",
      "\t is_intervened_by_week11 : Coef:     1.0099, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:    -0.4449, p_val:  0.000\n",
      "\t is_intervened_by_week11 : Coef:     1.8138, p_val:  0.000\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0723, p_val:  0.207\n",
      "\t is_intervened_by_week11 : Coef:     0.3012, p_val:  0.000\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# some helper dicts so as to make code cleaner\n",
    "mask_cols = ['control', 'round_robin', 'rmab']\n",
    "dummy_drop_cols = ['exp_arm_rr', 'exp_arm_rr', 'exp_arm_rmab']\n",
    "dummy_target_cols = ['exp_arm_rmab', 'exp_arm_rmab', 'exp_arm_rr']\n",
    "exps = ['RMAB vs RR', 'RMAB vs Control', 'RR vs Control']\n",
    "\n",
    "for t in range(1, T):\n",
    "    print(f'Significance for T = {t}\\n')\n",
    "    for m, d, tar, e in zip(mask_cols, dummy_drop_cols, dummy_target_cols, exps):\n",
    "        print(f'\\t{e}')\n",
    "        # make dataframe of our Y matrix. use mask to filter on group A, B only for A vs B comparision\n",
    "        # note that we use Y_mat, for our original paper's cumulative outcome variable\n",
    "        Y_mat_df = pd.DataFrame(Y_mat[t][mask[m]==0]-Y_mat[0][mask[m]==0],\n",
    "                                columns = ['output'])\n",
    "        # For A vs B comparision, column indicating arm C can be dropped\n",
    "        test_X_mat_df = X_mat_df.drop(columns=d)[mask[m]==0]\n",
    "        # add additional variable of is_intervened_by_week_t using interv_X_mat_df defined earlier\n",
    "        test_X_mat_df[f'is_intervened_by_week{t}'] = interv_X_mat_df[f'is_intervened_by_week{t}']\n",
    "        # both X and Y dataframes should have same indices else statsmodel throws error\n",
    "        test_X_mat_df.index = np.array(Y_mat_df.index)\n",
    "        # add constant term to the features, and then apply variance selector\n",
    "        test_X_mat_df = variance_threshold_selector(sm.add_constant(test_X_mat_df), 0.0001)\n",
    "\n",
    "        # define and fit the model\n",
    "        # note that here we use OLS model for continious outcome var\n",
    "        mod = sm.OLS(Y_mat_df, test_X_mat_df)\n",
    "        fii = mod.fit()\n",
    "        \n",
    "        # the output will have significances in the same order as input dataframe's columns\n",
    "        # tar is the A vs B comparisions dummy indicator\n",
    "        # look for its position in original columns\n",
    "        index = list(test_X_mat_df.columns).index(tar)\n",
    "        # Get data corresponding to our required variable using the index\n",
    "        # note that we do index + 1 because statsmodel table has header as first entry\n",
    "        var, coef, std_err, t_val, p_val, q1, q3 = fii.summary().tables[1].data[index+1]\n",
    "        print(f'\\t exp: Coef: {coef}, p_val: {p_val}')\n",
    "\n",
    "        try:\n",
    "            # do the same process as above to find signficance of is_intervened_by_week_t variable\n",
    "            index = list(test_X_mat_df.columns).index(f'is_intervened_by_week{t}')\n",
    "            var, coef, std_err, t_val, p_val, q1, q3 = fii.summary().tables[1].data[index+1]\n",
    "            print(f'\\t is_intervened_by_week{t} : Coef: {coef}, p_val: {p_val}')\n",
    "        except:\n",
    "            # note that this code is in try except block because for week 1, is_intervened_by_week_1\n",
    "            # is constant and gets dropped through variance selector function\n",
    "            pass\n",
    "\n",
    "#         print(fii.summary().tables[1])\n",
    "        print('\\n')\n",
    "    print('~'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58798351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance for T = 1\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0094, p_val:  0.135\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0066, p_val:  0.295\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0027, p_val:  0.671\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 2\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0225, p_val:  0.036\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0183, p_val:  0.088\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0039, p_val:  0.715\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 3\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0269, p_val:  0.075\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0170, p_val:  0.254\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0094, p_val:  0.531\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 4\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0335, p_val:  0.084\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0157, p_val:  0.414\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0173, p_val:  0.371\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 5\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0359, p_val:  0.130\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0258, p_val:  0.270\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0093, p_val:  0.692\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 6\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0339, p_val:  0.226\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0278, p_val:  0.316\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:    -0.0053, p_val:  0.851\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 7\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0349, p_val:  0.284\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0382, p_val:  0.234\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:     0.0041, p_val:  0.900\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 8\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0365, p_val:  0.324\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0471, p_val:  0.197\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:     0.0111, p_val:  0.762\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 9\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0359, p_val:  0.388\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0549, p_val:  0.179\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:     0.0196, p_val:  0.633\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 10\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0371, p_val:  0.418\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0714, p_val:  0.114\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:     0.0351, p_val:  0.439\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Significance for T = 11\n",
      "\n",
      "\tRMAB vs RR\n",
      "\t exp: Coef:     0.0402, p_val:  0.424\n",
      "\n",
      "\n",
      "\tRMAB vs Control\n",
      "\t exp: Coef:     0.0865, p_val:  0.081\n",
      "\n",
      "\n",
      "\tRR vs Control\n",
      "\t exp: Coef:     0.0472, p_val:  0.342\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# some helper dicts so as to make code cleaner\n",
    "mask_cols = ['control', 'round_robin', 'rmab']\n",
    "dummy_drop_cols = ['exp_arm_rr', 'exp_arm_rr', 'exp_arm_rmab']\n",
    "dummy_target_cols = ['exp_arm_rmab', 'exp_arm_rmab', 'exp_arm_rr']\n",
    "exps = ['RMAB vs RR', 'RMAB vs Control', 'RR vs Control']\n",
    "\n",
    "for t in range(1, T):\n",
    "    print(f'Significance for T = {t}\\n')\n",
    "    for m, d, tar, e in zip(mask_cols, dummy_drop_cols, dummy_target_cols, exps):\n",
    "        print(f'\\t{e}')\n",
    "        # make dataframe of our Y matrix. use mask to filter on group A, B only for A vs B comparision\n",
    "        # note that we use Y_mat, for our original paper's cumulative outcome variable\n",
    "        Y_mat_df = pd.DataFrame(Y_mat[t][mask[m]==0]-(t+1)*Y_mat[0][mask[m]==0],\n",
    "                                columns = ['output'])\n",
    "        # For A vs B comparision, column indicating arm C can be dropped\n",
    "        test_X_mat_df = X_mat_df.drop(columns=d)[mask[m]==0]\n",
    "        # add additional variable of is_intervened_by_week_t using interv_X_mat_df defined earlier\n",
    "#         test_X_mat_df[f'is_intervened_by_week{t}'] = interv_X_mat_df[f'is_intervened_by_week{t}']\n",
    "        # both X and Y dataframes should have same indices else statsmodel throws error\n",
    "        test_X_mat_df.index = np.array(Y_mat_df.index)\n",
    "        # add constant term to the features, and then apply variance selector\n",
    "        test_X_mat_df = variance_threshold_selector(sm.add_constant(test_X_mat_df), 0.0001)\n",
    "\n",
    "        # define and fit the model\n",
    "        # note that here we use OLS model for continious outcome var\n",
    "        mod = sm.OLS(Y_mat_df, test_X_mat_df)\n",
    "        fii = mod.fit()\n",
    "        \n",
    "        # the output will have significances in the same order as input dataframe's columns\n",
    "        # tar is the A vs B comparisions dummy indicator\n",
    "        # look for its position in original columns\n",
    "        index = list(test_X_mat_df.columns).index(tar)\n",
    "        # Get data corresponding to our required variable using the index\n",
    "        # note that we do index + 1 because statsmodel table has header as first entry\n",
    "        var, coef, std_err, t_val, p_val, q1, q3 = fii.summary().tables[1].data[index+1]\n",
    "        print(f'\\t exp: Coef: {coef}, p_val: {p_val}')\n",
    "\n",
    "        try:\n",
    "            # do the same process as above to find signficance of is_intervened_by_week_t variable\n",
    "            index = list(test_X_mat_df.columns).index(f'is_intervened_by_week{t}')\n",
    "            var, coef, std_err, t_val, p_val, q1, q3 = fii.summary().tables[1].data[index+1]\n",
    "            print(f'\\t is_intervened_by_week{t} : Coef: {coef}, p_val: {p_val}')\n",
    "        except:\n",
    "            # note that this code is in try except block because for week 1, is_intervened_by_week_1\n",
    "            # is constant and gets dropped through variance selector function\n",
    "            pass\n",
    "\n",
    "#         print(fii.summary().tables[1])\n",
    "        print('\\n')\n",
    "    print('~'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61b59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
